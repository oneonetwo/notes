# HTTP协议
> 超文本传输协议 Hyper Text Transfer Protocol  
  [思维导图](https://static001.geekbang.org/resource/image/27/cc/2781919e73f5d258ff1dc371af632acc.png)
### 前言 
1. HTTP是什么，不是什么
   - HTTP 是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范
2. http前世今生
    - 前期诞生
      > 1. URI：即统一资源标识符，作为互联网上资源的唯一身份；
      > 2. HTML：即超文本标记语言，描述超文本文档；
      > 3. HTTP：即超文本传输协议，用来传输超文本。
    - http/0.9
      > 1. 只允许用“GET”动作从服务器上获取 HTML 文档，并且在响应请求之后立即关闭连接，功能非常有限。
    - HTTP/1.0
      > 1. 增加了 HEAD、POST 等新方法；
      > 2. 增加了响应状态码，标记可能的错误原因；
      > 3. 引入了协议版本号概念；
      > 4. 引入了 HTTP Header（头部）的概念，让 HTTP 处理请求和响应更加灵活；
      > 5. 传输的数据不再仅限于文本。
    - HTTP/1.1
      > 1. 增加了 PUT、DELETE 等新的方法；
      > 2. 增加了缓存管理和控制；`catch-control: no-cache`
      > 3. 管道机制，允许持久连接；在同一个TCP连接里面，客户端可以同时发送多个请求，一个TCP连接现在可以传送多个回应，`Content-length`字段的作用，声明本次回应的数据长度。
      一个域名大多数浏览器允许同时建立6个持久连接,`Connection: keep-live`
      > 4. 允许响应数据分块（chunked），利于传输大文件；`transfer-enconding： chunked`
      > 5. 强制要求 Host 头，让互联网主机托管成为可能。
      > 6. **缺点**
      >> - 复用TCP连接，但是同一个TCP连接里面，所有的数据通信是按次序进行的。服务器只有处理完一个回应，才会进行下一个回应。要是前面的回应特别慢，后面就会有许多请求排队等着。这称为"队头堵塞"（Head-of-line blocking）。    
      > 7. **优化** 
      >> - **并发连接** 同时对一个域名发起多个长连接，用数量来解决质量的问题。
      >> - **域名分片** 这些域名都指向同一台服务器,这样实际长连接的数量就又上去了
      >> - **减少请求数** 比如合并脚本和样式表、将图片嵌入CSS
    - HTTP/2.0
      > 1. HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为"帧"（frame）：**头信息帧和数据帧**
      > 2. HTTP/2 复用TCP连接，在一个连接里，客户端和浏览器都可以同时发送多个请求或回应，而且不用按照顺序一一对应，这样就避免了"队头堵塞"。
举例来说，在一个TCP连接里面，服务器同时收到了A请求和B请求，于是先回应A请求，结果发现处理过程非常耗时，于是就发送A请求已经处理好的部分， 接着回应B请求，完成后，再发送A请求剩下的部分。这样双向的、实时的通信，就叫做**多工**（Multiplexing）。
      > 3. HTTP/2 对这一点做了优化，引入了**头信息压缩机制**（header compression）。一方面，头信息使用gzip或compress压缩后再发送；另一方面，客户端和服务器同时维护一张头信息表，所有字段都会存入这个表，生成一个索引号，以后就不发送同样字段了，只发送索引号，这样就提高速度了。
      > 4. HTTP/2 允许服务器未经请求，主动向客户端发送资源，这叫做**服务器推送**（server push）。
      > 5. 增强了安全性，“事实上”要求加密通信。
    - Https跟http区别
      > 1. http标准端口是80  https:443
      > 2. http不安全,明文传输  https是ssl加密传输协议
      > 3. https需要SSL证书， 需要交费，
      > 4. http工作在应用层，建立在tcp/IP之上
      > 5. https就是在http下加了一层，https的传输协议由TCP换成了SSL  
        >> 1. 非对称加密，对称加密，数字签名和证书
        >> 2. HTTPS 连接大致上可以划分为两个部分，第一个是建立连接时的非对称加密握手，第二个是握手后的对称加密报文传输。
        >> 3. 在tcp建立连接之后，开始建立ssl连接，浏览器先发送随机数，密码套件，浏览器返回密码套件，随机数，证书，公钥，实现密钥交换，
      第一个往返消息结束，然后客户端验证签名证书，根据返回的密码套件生成公钥，发给服务器，然后客户端跟服务端根据随机数生成会话秘钥。然后就收发加密的http的请求和响应了。      

3. 概念
    - 浏览器: 浏览器是 HTTP 协议里的请求方，即 User Agent；
    - Web 服务器: HTTP 协议里的应答方，常用的有 Apache 和 Nginx；
    - CDN, 全称是“Content Delivery Network”，翻译过来就是“内容分发网络”。它应用了 HTTP 协议里的缓存和代理技术，代替源站响应客户端的请求。
    - 爬虫， 是另一类 User Agent，是自动访问网络资源的程序。
    - HTML，是超文本标记语言，使用各种标签描述文字、图片、超链接等资源，并且可以嵌入 CSS、JavaScript 等技术实现复杂的动态效果，复杂的非线性、网状的结构关系，再经过浏览器的解释，呈现在我们面前的就是一个含有多种视听信息的页面
    - WebService，一个基于 Web（HTTP）的服务架构技术，既可以运行在内网，也可以在适当保护后运行在外网。
    - WAF，网络应用防火墙，它是应用层面的“防火墙”，专门检测 HTTP 流量，是防护 Web 应用的安全技术。
### HTTP相关协议
1. TCP/IP协议
    -  TCP/IP 协议实际上是一系列网络通信协议的统称，其中最核心的两个协议是 TCP 和 IP，
    -  IP 协议是“Internet Protocol”的缩写，主要目的是解决寻址和路由问题，以及如何在两点间传送数据包。
    -  TCP 协议是“Transmission Control Protocol”的缩写，意思是“传输控制协议”，它位于 IP 协议之上，基于 IP 协议提供可靠的、字节流形式的通信，是 HTTP 协议得以实现的基础。
    -  HTTP 是一个"传输协议"，但它不关心寻址、路由、数据完整性等传输细节，而要求这些工作都由下层来处理。因为互联网上最流行的是 TCP/IP 协议，而它刚好满足 HTTP 的要求，所以互联网上的 HTTP 协议就运行在了 TCP/IP 上，HTTP 也就可以更准确地称为“HTTP over TCP/IP”。
2. DNS 为了方便访问互联网上的 Web 服务器，通常都会使用 DNS 来定位或标记主机名，间接地把 DNS 与 HTTP 绑在了一起。
3. URI/URL
    - URI（Uniform Resource Identifier），中文名称是 统一资源标识符，使用它就能够唯一地标记互联网上资源。
    - URL（Uniform Resource Locator）， 统一资源定位符，也就是我们俗称的“网址”
4. HTTPS
    - 全称是 “HTTP over SSL/TLS”，也就是运行在 SSL/TLS 协议上的 HTTP。
    - SSL 使用了许多密码学最先进的研究成果，综合了对称加密、非对称加密、摘要算法、数字签名、数字证书等技术，能够在不安全的环境中为通信的双方创建出一个秘密的、安全的传输通道，为 HTTP 套上一副坚固的盔甲。
5. 代理
    - 代理有很多的种类，常见的有：
      > 1. 匿名代理：完全“隐匿”了被代理的机器，外界看到的只是代理服务器；
      > 2. 透明代理：顾名思义，它在传输过程中是“透明开放”的，外界既知道代理，也知道客户端；
      > 3. 正向代理：靠近客户端，代表客户端向服务器发送请求；
      > 4. 反向代理：靠近服务器端，代表服务器响应客户端的请求； 
    - 由于代理在传输过程中插入了一个“中间层”，所以可以在这个环节做很多有意思的事情，比如：
      > 1. 负载均衡：把访问请求均匀分散到多台机器，实现访问集群化；
      > 2. 内容缓存：暂存上下行的数据，减轻后端的压力；
      > 3. 安全防护：隐匿 IP, 使用 WAF 等工具抵御网络攻击，保护被代理的机器；
      > 4. 数据处理：提供压缩、加密等额外的功能。
      
### 经典网络分层模型   
1. 物理层, 网络的物理形式，例如电缆、光纤、网卡、集线器等等；
2. 数据链路层, 负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次 ,使用 MAC 地址来标记网络上的设备
3. 网络层, IP 协议就处在这一层,用 IP 地址取代 MAC 地址，把许许多多的局域网、广域网连接成一个虚拟的巨大网络
4. 传输层,这个层次协议的职责是保证数据在 IP 地址标记的两点之间“可靠”地传输，是 TCP 协议工作的层次，另外还有它的一个“小伙伴”UDP。
5. 应用层,例如 Telnet、SSH、FTP、SMTP 等等，当然还有我们的 HTTP。

### 基础篇

1. 浏览器按下回车键，发生了什么？
      - 首先浏览器看需不需要redirect（有可能浏览器已经做了记录），需要redirect到哪里 ,
      - 第二步去看app cache 是否有缓存，然后去请求资源，
      - 经过DNS解析，获取IP后，
      - 创建TCP链接，经过TCP三次握手（如果是https则跟tcp不一样)
      - 建立 TCP 连接后会顺序收发数据，请求方和应答方都必须依据 HTTP 规范构建和解析报文
      - 浏览器解析报文，渲染输出页面。
2. HTTP报文  
      <img src="https://static001.geekbang.org/resource/image/b1/df/b191c8760c8ad33acd9bb005b251a2df.png" width="80%">
      - 请求行 `GET /HTTP/1.1`
      - 状态行 `HTTP/1.1 200 OK`
      - 起始行和头部字段经常又合称为“请求头”或“响应头”，消息正文又称为“实体”，但与“header”对应，很多时候就直接称为“body”。
      
3. 请求方法  GET head POST  PUT patch trace  options  
      - GET：获取资源，可以理解为读取或者下载数据；
      - HEAD：方法与 GET 方法类似,但服务器不会返回请求的实体数据，只会传回响应头，也就是资源的“元信息”
      - POST：发送数据给服务器.更新数据；
      - PUT：类似 POST,用于新增资源调用一次与连续调用多次是等价的（即没有副作用）；
      - Get跟Post区别
         > 1. http定义的语义化的请求方法get获取数据，post发送数据给服务器
         > 2. get参数通过url传递，post放在request body中，所以get请求在传递的参数是有长度限制的，post没有，可以上传数据文件
         > 3. Get是不安全的，因为在传输过程，数据被放在请求的URL中，而如今现有的很多服务器、代理服务器或者用户代理都会将请求URL记录到日志文件中，然后放在某个地方，这样就可能会有一些隐私的信息被第三方看到。另外，用户也可以在浏览器上直接看到提交的数据，一些系统内部消息将会一同显示在用户面前。Post的所有操作对用户来说都是不可见的。
         > 4. get请求会浏览器主动cache，保留在浏览历史记录里，而post中的参数不会被保留。
4. 响应状态码
    - 1××：提示信息，表示目前是协议处理的中间状态，还需要后续的操作；
      > 1. `101 Switching Protocols` 要求在 HTTP 协议的基础上改成其他的协议继续通信，比如 WebSocket。而如果服务器也同意变更协议，就会发送状态码 101，但这之后的数据传输就不会再使用 HTTP 了。
    - 2××：成功，报文已经收到并被正确处理；
      > 1. `200 OK`正确的请求返回正确的结果，如果不想细分正确的请求结果都可以直接返回200。
      > 2. `202 Accepted` 请求是正确的，但是结果正在处理中，这时候客户端可以通过轮询等机制继续请求。
      > 3. `203 Non-Authoritative Information` 请求的代理服务器修改了源服务器返回的 200 中的内容，我们通过代理服务器向服务器 A 请求用户信息，服务器 A 正常响应，但代理服务器命中了缓存并返回了自己的缓存内容，这时候它返回 203 告诉我们这部分信息不一定是最新的，我们可以自行判断并处理。
      > 4. `206 Partial Content` 是 HTTP 分块下载或断点续传的基础，在客户端发送“范围请求”、要求获取资源的部分数据时出现，它与 200 一样，也是服务器成功处理了请求，但 body 里的数据不是资源的全部，而是其中的一部分。  
      状态码 206 通常还会伴随着头字段“Content-Range”，表示响应报文里 body 数据的具体范围，供客户端确认，例如“Content-Range: bytes 0-99/2000”，意思是此次获取的是总计 2000 个字节的前 100 个字节。
    - 3××：重定向，资源位置发生变动，需要客户端重新发送请求；
      > 1. `301 Moved Permanently` 俗称“永久重定向”，含义是此次请求的资源已经不存在了，需要改用改用新的 URI 再次访问。
      > 2. `302 Found` 俗称“临时重定向”，意思是请求的资源还在，但需要暂时用另一个 URI 来访问。
      > 3. `304 Not Modified` 是一个比较有意思的状态码，它用于 If-Modified-Since 等条件请求，表示资源未修改，用于缓存控制。
    - 4××：客户端错误，请求报文有误，服务器无法处理；
      > 1. `400 Bad Request` 是一个通用的错误码，表示请求报文有错误.
      > 2. `401 Unauthorized` 没有提供认证信息。请求的时候没有带上 Token 等。
      > 3. `403 Forbidden` 表示服务器禁止访问资源,说没有权限
      > 4. `404 Not Found` 请求的内容不存在。
      > 5. `405 Method Not Allowed`：不允许使用某些方法操作资源，例如不允许 POST 只能 GET；
      > 6. `408 Request Timeout`：请求超时，服务器等待了过长的时间；
      > 7. `413 Request Entity Too Large`：请求报文里的 body 太大；
    - 5××：服务器错误，服务器在处理请求时内部发生了错误。
      > 1. `500 Internal Server Error`内部服务器错误
      > 2. `501 Not Implemented` 表示客户端请求的功能还不支持，
      > 3. `502 Bad Gateway`通常是服务器作为网关或者代理时返回的错误码，表示服务器自身工作正常，
      > 4. `503 Service Unavailable`表示服务器当前很忙，暂时无法响应服务
    - **301根302的区别**
      > 1. 301会告诉浏览器下次请求直接到新连接就行并且每次会从浏览器缓存中读取内容，只有当用户清除浏览器的缓存才能重新从服务器获取数据
      > 2. 搜索引擎的爬虫看到 301，也会更新索引库，不再使用老的 URI。浏览器或者爬虫看到 302，会认为原来的 URI 仍然有效，但暂时不可用，下次访问还是用原 URI。
      > 3. 性能损耗，一次“重定向”实际上发送了两次 HTTP 请求，第一次请求返回响应头字段 Location 指示了要跳转的 URI
5. 数据协商  

    | 客户端 | =》 | 服务端 |
    | -----： | :----: | :----- |
    | Accept | 接受的类型 | content-Type |
    | Accept-Encoding | 限制服务端数据压缩的方式 | content-Encoding |
    |	Accept-Language | 语言 | content-language |
    |	User-agent | 浏览器的想灌的信息 | 
    
6. HTTP传输大文件的方法
    - 通常浏览器在发送请求时都会带着 `Accept-Encoding` 头字段，里面是浏览器支持的压缩格式列表，例如 gzip、deflate、br 等，这样服务器就可以从中选择一种压缩算法，放进 `Content-Encoding` 响应头里，再把原数据压缩后发给浏览器。
    - `chunked`分块传输编码
      > 1. 在响应报文里用头字段 `Transfer-Encoding: chunked`   
      > 2. “Transfer-Encoding: chunked”和“Content-Length”这两个字段是互斥的,一个响应报文的传输要么是长度已知，要么是长度未知（chunked），这一点你一定要记住。
    - 范围请求 比如，你在看当下正热播的某穿越剧，想跳过片头，直接看正片，或者有段剧情很无聊，想拖动进度条快进几分钟
      > 1. 允许客户端在请求头里使用专用字段来表示只获取文件的一部分，相当于是客户端的“化整为零”。
      > 2. 服务器必须在响应头里使用字段 `Accept-Ranges: bytes`明确告知客户端：“我是支持范围请求的”,服务器要添加一个响应头字段 Content-Range
    - 多段数据, 一次性获取多个片段数据。

7. cookie 
    - 响应头字段 Set-Cookie 和请求头字段 Cookie, 响应报文使用 Set-Cookie 字段发送“key=value”形式的 Cookie 值；请求报文里用 Cookie 字段发送多个 Cookie 值；
    - Max-Age(长度)、Expires（节点）设置过期的时间， Domain、HttpOnly、Secure
    - 另一个属性“SameSite”可以防范“跨站请求伪造”（XSRF）攻击，设置成“SameSite=Strict”可以严格限定 Cookie 不能随着跳转链接跨站发送
    - 不能跨域设置cookie  ，二级域名能共享主域名的cookie
    - 应用场景
      > 1. 基本的一个用途是身份识别，保存用户的登录信息，实现会话事务
      > 2. 另一个常见用途是广告跟踪
8. 缓存 cache-control ,节约网络带宽，也可以加快响应速度
    - 可缓存性
      > 1. Pulic 可以在浏览器，中间代理都可以缓存这个http请求的内容
      > 2. Private 只有发起请求的浏览器可缓存
      > 3. No-cache 可以使用本地，代理缓存，但是需要经过服务器的验证
    - 有限期 max-age=<seconds>   浏览器的缓存到期时间, 
    - No-store 不能使用缓存，必须去服务器请求，
    - No-transform  告诉代理服务器不要改变返回的内容
    - Ctrl+F5 的“强制刷新”又是什么样的呢？ 它其实是发了一个“Cache-Control: no-cache”
    - 缓存资源验证（cache-control设置no-cache需要做验证）  验证头
      > 1. 最常用的是“if-Modified-Since”和“If-None-Match”这两个。需要第一次的响应报文预先提供“Last-modified”和“ETag”，然后第二次请求时就可以带上缓存里的原值，验证资源是否是最新的。

### HTTP的客户端
1. 浏览器跨域的限制（同源策略时浏览器的限制）
    - 浏览器允许link script img 标签加载一些内容，  
  Jsonp就是script标签加载一个链接，去访问服务器的某一个请求，并返回内容，因为服务器返回的内容是可控的，所以在请求之前，调用jsonp，返回一段调用某个函数的js代码，在src中进行了调用，这样实现了跨域
    - 跨域资源共享(CORS)  CORS跨域限制
      > 1. 跨域允许的方法： get  post   head
      > 2. 允许的Content-type   text/plain     multipart/form-data   application/x-ww.
      > 3. Cors预请求验证
      >> * options 通过options发送一个服务端的认可的请求 ，在发送post请求
      >> * Max-Age 1000秒之内不需要预请求进行验证    
      
              response.writeHead(200, {
                'Access-Control-Allow-Origin': 'http://127.0.0.1:8888',
                'Access-Control-Allow-Headers': 'X-Test-Cors',
                'Access-Control-Allow-Methods': 'POST, PUT, DELETE',
                'Access-Control-Max-Age': '1000'
              })
2. webSocjet

  
  


  
  
